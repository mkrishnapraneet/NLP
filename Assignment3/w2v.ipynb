{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import collections\n",
    "import itertools\n",
    "from sklearn.manifold import TSNE\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 61653\n",
      "['this', 'has', 'some', 'great', 'tips', 'as', 'always', 'and', 'is', 'helping', 'me', 'to', 'complete', 'my', 'good', 'eats', 'collection', '.']\n"
     ]
    }
   ],
   "source": [
    "input_file = '../../reviews_Movies_and_TV.json'\n",
    "# input_file = 'try.json'\n",
    "\n",
    "# Load the data\n",
    "sentences = []\n",
    "counter = 0\n",
    "with open(input_file, 'r') as f:\n",
    "    for line in f:\n",
    "        if counter > 10000:\n",
    "            break\n",
    "        # add each sentence as a list of words to the sentences list, but each line of the json object is a document containing multiple sentences\n",
    "        # sentences.append(word_tokenize(json.loads(line)['reviewText']))\n",
    "        doc_sentences = sent_tokenize(json.loads(line)['reviewText'])\n",
    "        # sentences.append([word_tokenize(sentence) for sentence in doc_sentences])\n",
    "        for sentence in doc_sentences:\n",
    "            sentences.append([word.lower() for word in word_tokenize(sentence)])\n",
    "        counter += 1\n",
    "        \n",
    "\n",
    "print('Number of sentences: {}'.format(len(sentences)))\n",
    "print(sentences[0])\n",
    "\n",
    "# for sentence in sentences:\n",
    "#     print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 9926\n",
      "The 10 most common words are: \n",
      "[('the', 66180), ('.', 53197), (',', 48894), ('and', 35071), ('of', 31487), ('to', 30637), ('a', 27801), ('i', 23909), ('is', 22758), ('it', 21689)]\n"
     ]
    }
   ],
   "source": [
    "# form the vocabulary\n",
    "# Flatten the list of sentences into a single list of words\n",
    "words = itertools.chain.from_iterable(sentences)\n",
    "\n",
    "# Create a Counter object to count the frequency of each word\n",
    "word_counter = collections.Counter(words)\n",
    "\n",
    "# Extract the unique words from the Counter object to form the vocabulary\n",
    "min_freq = 5\n",
    "# vocabulary = set(word_counter.keys())\n",
    "# vocabulary = set(word for word, count in word_counter.items() if count >= min_freq)\n",
    "# add the word if it occurs more than min_freq times, else add <unk> token\n",
    "vocabulary = set(word if count >= min_freq else '<unk>' for word, count in word_counter.items())\n",
    "\n",
    "# add the <pad> token\n",
    "vocabulary.add('<pad>')\n",
    "\n",
    "# Print the size of the vocabulary\n",
    "print('Vocabulary size: {}'.format(len(vocabulary)))\n",
    "\n",
    "# Create a dictionary to map each word to an index\n",
    "word2idx = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "\n",
    "# Create a dictionary to map each index to a word\n",
    "idx2word = {idx: word for idx, word in enumerate(vocabulary)}\n",
    "\n",
    "# print the 10 most common words\n",
    "print('The 10 most common words are: ')\n",
    "print(word_counter.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data for training\n",
    "window_size = 2\n",
    "sliding_window_size = window_size*2 + 1\n",
    "num_neg_samples_per_context = 3\n",
    "\n",
    "vocab_indices = list(word2idx.values())\n",
    "vocab_size = len(vocab_indices)\n",
    "\n",
    "# create data with X being indices of the context words and the target word, and y being 0 or 1 based on whether the target word is correct for the context words\n",
    "# also add negative samples\n",
    "def create_data_with_negative_sampling(sentences, word2idx, window_size, num_neg_samples_per_context):\n",
    "    X = []\n",
    "    y = []\n",
    "    # counter = 0\n",
    "    for sentence in sentences:\n",
    "        for i in range(len(sentence)):\n",
    "            # a list of indices of context words and the target word\n",
    "            # if it goes out of bounds, add <pad> tokens            \n",
    "            context_words = sentence[max(0, i-window_size):i] + sentence[i+1:min(len(sentence), i+window_size+1)]\n",
    "            target_word = sentence[i]\n",
    "            # if the any of the words are not in the vocabulary, replace it with <unk>\n",
    "            context_words = [word if word in word2idx else '<unk>' for word in context_words]\n",
    "            target_word = target_word if target_word in word2idx else '<unk>'\n",
    "            \n",
    "            data_point = [word2idx[context_word] for context_word in context_words]\n",
    "            # if the size of the data point is less than the sliding window size, add <pad> tokens\n",
    "            # if len(data_point) < sliding_window_size:\n",
    "            data_point += [word2idx['<pad>']]*(sliding_window_size-len(data_point)-1)\n",
    "            data_point.append(word2idx[target_word])\n",
    "\n",
    "            # add this to X and y\n",
    "            X.append(data_point)\n",
    "            y.append(1)\n",
    "\n",
    "            # add negative samples\n",
    "            for _ in range(num_neg_samples_per_context):\n",
    "                # generate a random index between 0 and vocab_size\n",
    "                negative_word = random.randint(0, vocab_size-1)\n",
    "                X.append(data_point[:-1] + [negative_word])                \n",
    "                y.append(0)\n",
    "        # counter += 1\n",
    "        # print(counter)\n",
    "    return X, y \n",
    "            \n",
    "\n",
    "    #         # convert the words to indices and add to X as [target_index, context_index1]\n",
    "    #         for context_word in context_words:\n",
    "    #             data_point = [word2idx[target_word], word2idx[context_word]]\n",
    "    #             X.append(data_point)\n",
    "    #             y.append(1)\n",
    "    #             # add negative samples\n",
    "    #             for _ in range(num_neg_samples_per_context):\n",
    "    #                 # generate a random index between 0 and vocab_size\n",
    "    #                 negative_word = random.randint(0, vocab_size-1)\n",
    "    #                 X.append([word2idx[target_word], negative_word])                \n",
    "    #                 y.append(0)\n",
    "    # return X, y\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "X, y = create_data_with_negative_sampling(sentences, word2idx, window_size, num_neg_samples_per_context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# shuffle the data\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# split the data into train and test\n",
    "\n",
    "# save the data to a file so that it can be loaded later\n",
    "# np.savez('data.npz', X=X, y=y)\n",
    "\n",
    "# load the data from the file\n",
    "def load_data(filename):\n",
    "    data = np.load(filename)\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "    return X, y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 5352048\n",
      "Number of labels: 5352048\n",
      "index of <unk> is: 7258\n",
      "index of <pad> is: 2953\n",
      "[4447 3147 2953 2953 1033]   0\n",
      "[2734 7931 9892 8285  105]   0\n",
      "[9381 7931 9878 4561 3719]   0\n",
      "[8048 4787  448 2953 4066]   0\n",
      "[ 448 2953 2953 2953 4441]   1\n",
      "[ 389 3982  305 6232  430]   0\n",
      "[3054 3561 7931 2953 2062]   1\n",
      "[6198 1177 7258 9503  121]   0\n",
      "[4871 1177  448 2953 8354]   0\n",
      "[9183 7435 9498 8058 6802]   0\n",
      "[  94 2062  746 4324 1451]   1\n",
      "[9498 4324 9878 8204 5457]   1\n",
      "[4141 7742 6198 4582 2351]   0\n",
      "[5694 3799 2953 2953  448]   1\n",
      "[9289 2062 9593 8486 5281]   0\n",
      "[4447 2734 2381  448  591]   0\n",
      "[   6  824 6041 3117 3063]   0\n",
      "[7286 3377 4160  385 8856]   0\n",
      "[4871 9186 1193  906 5737]   0\n",
      "[6916 7095 2953 2953 1964]   0\n",
      "[9425 1823 3982 6258 5027]   0\n",
      "[ 746 9186 1432 2734 5437]   0\n",
      "[1052 7112 2359 2062 7707]   0\n",
      "[ 427 7965 2355 9289 2531]   0\n",
      "[2062 3658 1160 5851 9185]   0\n",
      "[1136 9878 8184 6810 3962]   0\n",
      "[7469  533 7050 9498 3939]   1\n",
      "[ 646 9593 5443  191 9500]   0\n",
      "[9498  823 4160  281 5405]   0\n",
      "[8445  533 1177 4073 1540]   0\n",
      "[3236 6169 8996  869 2410]   0\n",
      "[2062 8689 9004 6614 2362]   0\n",
      "[9498 7258 2062 7258 2590]   1\n",
      "[7886 9289 3213 4498 4495]   0\n",
      "[3982 7258 4447 6198 7759]   0\n",
      "[4136 9498 2953 2953  248]   0\n",
      "[2062 2960 8577  614 2206]   0\n",
      "[2280 5516 5216  448 3089]   0\n",
      "[6503 9498 1177 6957 7854]   0\n",
      "[2734 7808 2062 2114  827]   0\n",
      "[9593 2734 9183  969 1968]   0\n",
      "[7258 9498 9712 5468 7976]   0\n",
      "[1177 5163  448 2953 6038]   0\n",
      "[4561  987  448 2953 4779]   0\n",
      "[8645 2815 9242 3042 5639]   0\n",
      "[1155 7931 9912 7931 8734]   0\n",
      "[2062 1327 2953 2953 2193]   0\n",
      "[3511 2461 2953 2953 5776]   0\n",
      "[ 746 5280 4871   42 4660]   0\n",
      "[6198 6464 9183 1941 3134]   0\n"
     ]
    }
   ],
   "source": [
    "print('Number of data points: {}'.format(len(X)))\n",
    "print('Number of labels: {}'.format(len(y)))\n",
    "\n",
    "# print(vocab_indices)\n",
    "print('index of <unk> is: {}'.format(word2idx['<unk>']))\n",
    "print('index of <pad> is: {}'.format(word2idx['<pad>']))\n",
    "\n",
    "for i in range (50):\n",
    "    print('{}   {}'.format(X[i], y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a model to learn the word embeddings from the data generated above\n",
    "\n",
    "# define the model\n",
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "        # self.linear1 = nn.Linear(embedding_size, vocab_size)\n",
    "        # self.linear2 = nn.Linear(vocab_size, embedding_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is a list of indices of context words and the target word\n",
    "        \n",
    "        # get the embeddings of the context words\n",
    "        context_embeddings = self.embeddings(x[:, :-1])\n",
    "        # get the embedding of the target word\n",
    "        target_embedding = self.embeddings(x[:, -1])\n",
    "\n",
    "        # get the average of the context embeddings\n",
    "        context_embeddings = torch.mean(context_embeddings, dim=1)\n",
    "\n",
    "        # get the dot product of the context embeddings and the target embedding\n",
    "        dot_product = torch.sum(context_embeddings*target_embedding, dim=1)\n",
    "        # get the sigmoid of the dot product\n",
    "        sigmoid = torch.sigmoid(dot_product)\n",
    "\n",
    "        # return the sigmoid as the prediction\n",
    "        return sigmoid\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        # get the embedding of the word with index x\n",
    "        return self.embeddings(x)\n",
    "    \n",
    "    def get_embeddings(self):\n",
    "        # get the embeddings of all the words\n",
    "        return self.embeddings.weight\n",
    "    \n",
    "    def get_embedding_size(self):\n",
    "        # get the size of the embeddings\n",
    "        return self.embedding_size\n",
    "    \n",
    "\n",
    "# define the hyperparameters\n",
    "vocab_size = len(vocab_indices)\n",
    "embedding_size = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 25\n",
    "\n",
    "# create the model\n",
    "model = Word2Vec(vocab_size, embedding_size).to(device)\n",
    "\n",
    "# define the loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# create the dataloader\n",
    "dataset = torch.utils.data.TensorDataset(torch.from_numpy(X).long(), torch.from_numpy(y).float())\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Step [10000/83626], Loss: 0.7988\n",
      "Epoch [1/25], Step [20000/83626], Loss: 0.4196\n",
      "Epoch [1/25], Step [30000/83626], Loss: 0.4507\n",
      "Epoch [1/25], Step [40000/83626], Loss: 0.2914\n",
      "Epoch [1/25], Step [50000/83626], Loss: 0.3116\n",
      "Epoch [1/25], Step [60000/83626], Loss: 0.5666\n",
      "Epoch [1/25], Step [70000/83626], Loss: 0.2891\n",
      "Epoch [1/25], Step [80000/83626], Loss: 0.5081\n",
      "Epoch [2/25], Step [10000/83626], Loss: 0.2305\n",
      "Epoch [2/25], Step [20000/83626], Loss: 0.2209\n",
      "Epoch [2/25], Step [30000/83626], Loss: 0.1703\n",
      "Epoch [2/25], Step [40000/83626], Loss: 0.3327\n",
      "Epoch [2/25], Step [50000/83626], Loss: 0.2669\n",
      "Epoch [2/25], Step [60000/83626], Loss: 0.3941\n",
      "Epoch [2/25], Step [70000/83626], Loss: 0.2030\n",
      "Epoch [2/25], Step [80000/83626], Loss: 0.1700\n",
      "Epoch [3/25], Step [10000/83626], Loss: 0.1459\n",
      "Epoch [3/25], Step [20000/83626], Loss: 0.3426\n",
      "Epoch [3/25], Step [30000/83626], Loss: 0.2755\n",
      "Epoch [3/25], Step [40000/83626], Loss: 0.2746\n",
      "Epoch [3/25], Step [50000/83626], Loss: 0.1780\n",
      "Epoch [3/25], Step [60000/83626], Loss: 0.3233\n",
      "Epoch [3/25], Step [70000/83626], Loss: 0.1921\n",
      "Epoch [3/25], Step [80000/83626], Loss: 1.8144\n",
      "Epoch [4/25], Step [10000/83626], Loss: 0.1465\n",
      "Epoch [4/25], Step [20000/83626], Loss: 0.1935\n",
      "Epoch [4/25], Step [30000/83626], Loss: 0.2445\n",
      "Epoch [4/25], Step [40000/83626], Loss: 0.2379\n",
      "Epoch [4/25], Step [50000/83626], Loss: 0.2366\n",
      "Epoch [4/25], Step [60000/83626], Loss: 0.2199\n",
      "Epoch [4/25], Step [70000/83626], Loss: 0.2191\n",
      "Epoch [4/25], Step [80000/83626], Loss: 1.6966\n",
      "Epoch [5/25], Step [10000/83626], Loss: 0.3201\n",
      "Epoch [5/25], Step [20000/83626], Loss: 0.3618\n",
      "Epoch [5/25], Step [30000/83626], Loss: 0.2248\n",
      "Epoch [5/25], Step [40000/83626], Loss: 0.4106\n",
      "Epoch [5/25], Step [50000/83626], Loss: 0.3015\n",
      "Epoch [5/25], Step [60000/83626], Loss: 0.2055\n",
      "Epoch [5/25], Step [70000/83626], Loss: 0.2692\n",
      "Epoch [5/25], Step [80000/83626], Loss: 0.1579\n",
      "Epoch [6/25], Step [10000/83626], Loss: 0.3074\n",
      "Epoch [6/25], Step [20000/83626], Loss: 0.2663\n",
      "Epoch [6/25], Step [30000/83626], Loss: 0.2749\n",
      "Epoch [6/25], Step [40000/83626], Loss: 0.0938\n",
      "Epoch [6/25], Step [50000/83626], Loss: 0.1704\n",
      "Epoch [6/25], Step [60000/83626], Loss: 0.0995\n",
      "Epoch [6/25], Step [70000/83626], Loss: 0.1038\n",
      "Epoch [6/25], Step [80000/83626], Loss: 0.1316\n",
      "Epoch [7/25], Step [10000/83626], Loss: 0.2036\n",
      "Epoch [7/25], Step [20000/83626], Loss: 0.2911\n",
      "Epoch [7/25], Step [30000/83626], Loss: 0.2358\n",
      "Epoch [7/25], Step [40000/83626], Loss: 0.3005\n",
      "Epoch [7/25], Step [50000/83626], Loss: 0.2176\n",
      "Epoch [7/25], Step [60000/83626], Loss: 0.1721\n",
      "Epoch [7/25], Step [70000/83626], Loss: 1.6171\n",
      "Epoch [7/25], Step [80000/83626], Loss: 0.1927\n",
      "Epoch [8/25], Step [10000/83626], Loss: 0.2311\n",
      "Epoch [8/25], Step [20000/83626], Loss: 0.2461\n",
      "Epoch [8/25], Step [30000/83626], Loss: 0.3551\n",
      "Epoch [8/25], Step [40000/83626], Loss: 0.0839\n",
      "Epoch [8/25], Step [50000/83626], Loss: 0.4629\n",
      "Epoch [8/25], Step [60000/83626], Loss: 0.1754\n",
      "Epoch [8/25], Step [70000/83626], Loss: 0.3679\n",
      "Epoch [8/25], Step [80000/83626], Loss: 0.1754\n",
      "Epoch [9/25], Step [10000/83626], Loss: 0.0863\n",
      "Epoch [9/25], Step [20000/83626], Loss: 0.1493\n",
      "Epoch [9/25], Step [30000/83626], Loss: 0.0968\n",
      "Epoch [9/25], Step [40000/83626], Loss: 0.1488\n",
      "Epoch [9/25], Step [50000/83626], Loss: 0.1942\n",
      "Epoch [9/25], Step [60000/83626], Loss: 0.3889\n",
      "Epoch [9/25], Step [70000/83626], Loss: 0.2835\n",
      "Epoch [9/25], Step [80000/83626], Loss: 0.1473\n",
      "Epoch [10/25], Step [10000/83626], Loss: 0.1527\n",
      "Epoch [10/25], Step [20000/83626], Loss: 0.2383\n",
      "Epoch [10/25], Step [30000/83626], Loss: 0.1372\n",
      "Epoch [10/25], Step [40000/83626], Loss: 0.2584\n",
      "Epoch [10/25], Step [50000/83626], Loss: 0.1254\n",
      "Epoch [10/25], Step [60000/83626], Loss: 0.2563\n",
      "Epoch [10/25], Step [70000/83626], Loss: 0.2582\n",
      "Epoch [10/25], Step [80000/83626], Loss: 1.6916\n",
      "Epoch [11/25], Step [10000/83626], Loss: 0.3458\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m \u001b[39m# forward pass\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m outputs \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     10\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     12\u001b[0m \u001b[39m# backward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[70], line 18\u001b[0m, in \u001b[0;36mWord2Vec.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     15\u001b[0m     \u001b[39m# x is a list of indices of context words and the target word\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \n\u001b[1;32m     17\u001b[0m     \u001b[39m# get the embeddings of the context words\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     context_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(x[:, :\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[1;32m     19\u001b[0m     \u001b[39m# get the embedding of the target word\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     target_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(x[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/sparse.py:160\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    161\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    162\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, labels) in enumerate(dataloader):\n",
    "        # move the data to the device\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10000 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(dataloader), loss.item()))\n",
    "    # print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "# save the model\n",
    "# torch.save(model.state_dict(), 'word2vec.ckpt')\n",
    "\n",
    "# load the model\n",
    "# model.load_state_dict(torch.load('word2vec.ckpt'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9926, 100)\n"
     ]
    }
   ],
   "source": [
    "# get the embeddings of all the words\n",
    "embeddings = model.get_embeddings().cpu().detach().numpy()\n",
    "\n",
    "# print the shape of the embeddings\n",
    "print(embeddings.shape)\n",
    "\n",
    "def cosine_similarity(x, y):\n",
    "    return np.dot(x, y)/(np.sqrt(np.sum(x**2))*np.sqrt(np.sum(y**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the 10 most similar words to the word 'king'\n",
    "def get_similar_words(word, embeddings, word2idx, idx2word, k=10):\n",
    "    # get the index of the word\n",
    "    word_idx = word2idx[word]\n",
    "    # get the embedding of the word\n",
    "    word_embedding = embeddings[word_idx]\n",
    "    # get the cosine similarity between the word embedding and all the other embeddings\n",
    "    similarities = []\n",
    "    for i in range(embeddings.shape[0]):\n",
    "        similarity = cosine_similarity(word_embedding, embeddings[i])\n",
    "        similarities.append(similarity)\n",
    "    # get the indices of the k most similar words\n",
    "    most_similar_indices = np.argsort(similarities)[-k:]\n",
    "    # get the words corresponding to the indices\n",
    "    most_similar_words = [idx2word[idx] for idx in most_similar_indices]\n",
    "    # print the most similar words in decreasing order of similarity\n",
    "    for i in range(k):\n",
    "        print('{}. {}'.format(i+1, most_similar_words[-(i+1)]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. titanic\n",
      "2. modes\n",
      "3. dan\n",
      "4. fade\n",
      "5. rewind\n",
      "6. najimy\n",
      "7. tennessee\n",
      "8. metronome\n",
      "9. netflix\n",
      "10. sadist\n"
     ]
    }
   ],
   "source": [
    "# print the 10 most similar words to the word 'king'\n",
    "get_similar_words('titanic', embeddings, word2idx, idx2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tnse to visualize the embeddings in 2D\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "word_vectors_2d = tsne.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # display the 10 closest words to each word in the words_to_visualise list in a 2D plot using word_vectors_2d using cosine similarity\n",
    "# def plot_words(words_to_visualise, word_vectors_2d, word2idx, idx2word):\n",
    "#     # get the indices of the words to visualize\n",
    "#     indices = [word2idx[word] for word in words_to_visualise]\n",
    "#     # get the embeddings of the words to visualize\n",
    "#     embs = [embeddings[idx] for idx in indices]\n",
    "#     # get the 10 most similar words to each word\n",
    "#     similar_words = []\n",
    "#     for i in range(len(words_to_visualise)):\n",
    "#         similar_words.append(get_similar_words(words_to_visualise[i], embs, word2idx, idx2word, k=10))\n",
    "#     # plot the words and their 10 most similar words\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     for i in range(len(words_to_visualise)):\n",
    "#         # plot the word\n",
    "#         plt.scatter(word_vectors_2d[indices[i], 0], word_vectors_2d[indices[i], 1], marker='x', color='red')\n",
    "#         plt.annotate(words_to_visualise[i], (word_vectors_2d[indices[i], 0], word_vectors_2d[indices[i], 1]))\n",
    "#         # plot the 10 most similar words\n",
    "#         for j in range(10):\n",
    "#             idx = word2idx[similar_words[i][j]]\n",
    "#             plt.scatter(word_vectors_2d[idx, 0], word_vectors_2d[idx, 1], marker='o', color='blue')\n",
    "#             plt.annotate(similar_words[i][j], (word_vectors_2d[idx, 0], word_vectors_2d[idx, 1]))\n",
    "#     plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m words_to_visualise \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mwoman\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minteresting\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39menjoy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mjohn\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmovie\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m plot_words(words_to_visualise, word_vectors_2d, word2idx, idx2word)\n",
      "Cell \u001b[0;32mIn[100], line 10\u001b[0m, in \u001b[0;36mplot_words\u001b[0;34m(words_to_visualise, word_vectors_2d, word2idx, idx2word)\u001b[0m\n\u001b[1;32m      8\u001b[0m similar_words \u001b[39m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(words_to_visualise)):\n\u001b[0;32m---> 10\u001b[0m     similar_words\u001b[39m.\u001b[39mappend(get_similar_words(words_to_visualise[i], embs, word2idx, idx2word, k\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m))\n\u001b[1;32m     11\u001b[0m \u001b[39m# plot the words and their 10 most similar words\u001b[39;00m\n\u001b[1;32m     12\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m10\u001b[39m))\n",
      "Cell \u001b[0;32mIn[97], line 6\u001b[0m, in \u001b[0;36mget_similar_words\u001b[0;34m(word, embeddings, word2idx, idx2word, k)\u001b[0m\n\u001b[1;32m      4\u001b[0m word_idx \u001b[39m=\u001b[39m word2idx[word]\n\u001b[1;32m      5\u001b[0m \u001b[39m# get the embedding of the word\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m word_embedding \u001b[39m=\u001b[39m embeddings[word_idx]\n\u001b[1;32m      7\u001b[0m \u001b[39m# get the cosine similarity between the word embedding and all the other embeddings\u001b[39;00m\n\u001b[1;32m      8\u001b[0m similarities \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# words_to_visualise = ['woman', 'interesting', 'enjoy', 'john', 'movie']\n",
    "\n",
    "# plot_words(words_to_visualise, word_vectors_2d, word2idx, idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embeddings\n",
    "np.save('w2v_embeddings.npy', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
