{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "('two options the us views the transitional national council as the sole / only legitimate interlocutor of the libyan people during this interim period , as libyans come together to plan their own future and a permanent , inclusive constitutional system that protects the rights of all libyans . <eos> this is in contrast to the qadhafi regime , which has lost all legitimacy to rule . <eos> the us views the transitional national council as the legitimate interlocutor of the libyan people during this interim period , as libyans come together to plan their own future and a permanent , inclusive constitutional system that protects the rights of all libyans . <eos> this is in contrast to the qadhafi regime , which has lost all legitimacy to rule . <eos> the inc is the institution through which we are engaging the libyan people at this time . <eos>', 3)\n",
      "(\"ambassador , we just received an email from the adoption service provider about these cases . <eos> i am currently reviewing the files to determine if they qualify within the guidelines established recently by uscis and dos . <eos> out of the 60 cases , 40 are being adopted by usc . <eos> out of the 40 , 5 of the cases were children escorted today and per cnn have just landed in miami . <eos> the remaining 35 we are reviewing now . <eos> some correspondence i 've seen says that they plan on bringing the children straight to the airport , and we have responded that they first need to come to the embassy . <eos> once case in particular will be an issue , as it requires the presidential waiver . <eos> did you receive the talking points about presidential waivers ? <eos> the majority of the cases will qualify for humanitarian parole . <eos> in the last 30 minutes a number of emails have been coming in about private planes , ted turner offering to fly children out , etc . <eos> we have a case coming in tomorrow morning in which the 2 adoptive families are being flown in by cbs helicopter from the dr . <eos> we are preparing as many cases in advance as possible tonight . <eos> kind regards , linda <eos>\", 1)\n",
      "(\"hillary , as you have been so kind to share your advice and mentorship with me in the past , i was hoping that we might find some time to chat about some of my current thinking . <eos> with the fabulous results of the presidents ' re - election , i am privileged to be able to continue to serve at the cftc . <eos> i recall your prior advice upon my being offered the post <eos> and it was invaluable . <eos> the challenges and opportunities to bring about common sense financial reforms have been fabulous . <eos> we are now moving beyond agency rule writing and helping the swaps markets transition to a new era of transparency and oversight . <eos> ( the cftc just completed final determinations such that the us has met the pittsburgh g-20 commitment deadline of december 2012 to have our swaps clearing mandate fully in place . ) <eos> if we might be able to find a moment to chat , i would love to share my thoughts on possible new challenges and opportunities within the administration . <eos> i hope all is well with you as well as you gear up for this holiday time and a much deserved break from the day to day stresses of your current post . <eos> gary <eos>\", 2)\n",
      "200\n",
      "(\"madame secretary : thank you for reaching out to secretary solis and convincing her to join the verification commission . <eos> she and ricardo lagos will make for a very high profile and effective international component of the commission . <eos> we will meet with her this morning at 10 am to brief her for tuesday 's journey to honduras . <eos> at this point , it appears we have a military aircraft available . <eos> the plan is for the u.s. delegation to depart d.c. , stop in miami to pick up ricardo lagos , and arrive in tegucigalpa together . <eos> we think this will send a powerful message to hondurans and leave no doubt about our commitment to seeing this process through to a successful conclusion . <eos> you should be aware that ambassador hugo llorens is under public assault . <eos> the wall street journal dedicates its america 's column this morning to attacking him and calling for his removal . <eos> last friday , representative connie mack did the same . <eos> this chorus will grow as the extent of our accomplishment is understood . <eos> llorens is a tough , stalwart guy . <eos> he and his mission have held firm during this crisis . <eos> a call from you would be a big boost . <eos> finally , we will hold an ipc today to identify further steps . <eos> we will keep you up to date on these steps and identify further opportunities for your engagement . <eos> i want to thank you for your leadership and support during this long crisis . <eos> your willingness to engage at key moments and take risks at the right time have propelled us much further than anyone expected . <eos> your diplomacy prevented a debilitating civil conflict in honduras that would have destabilized central america and undermined two decades of our efforts . <eos> we now have a big opportunity in front of us , and for that we are grateful to you . <eos> regards , tom <eos>\", 3)\n",
      "11943\n",
      "['another', 'luxor', 'wheldon', 'impinging', '10:21am', 'lessons', 'exciting', 'kanjorski', 'documenting', 'exaction']\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_inp_file = 'processed_data/GCDC/Clinton_train.jsonl'\n",
    "with open(train_inp_file, 'r') as f:\n",
    "    for line in f:\n",
    "        json_obj = json.loads(line)\n",
    "        # put <EOS> at the end of each sentence and add each sentence to the list\n",
    "        for i in range(len(json_obj['sentences'])):\n",
    "            json_obj['sentences'][i].append('<EOS>')\n",
    "        # merge all sentences into one\n",
    "        document = \" \".join([word for sentence in json_obj['sentences'] for word in sentence])\n",
    "        document = document.lower()\n",
    "        label = json_obj['label']\n",
    "        train_data.append((document, label))\n",
    "   \n",
    "\n",
    "test_data = []\n",
    "test_inp_file = 'processed_data/GCDC/Clinton_test.jsonl'\n",
    "with open(test_inp_file, 'r') as f:\n",
    "    for line in f:\n",
    "        json_obj = json.loads(line)\n",
    "        # put <EOS> at the end of each sentence and add each sentence to the list\n",
    "        for i in range(len(json_obj['sentences'])):\n",
    "            json_obj['sentences'][i].append('<EOS>')\n",
    "        # merge all sentences into one\n",
    "        document = \" \".join([word for sentence in json_obj['sentences'] for word in sentence])\n",
    "        document = document.lower()\n",
    "        label = json_obj['label']\n",
    "        test_data.append((document, label))\n",
    "        \n",
    "print(len(train_data))\n",
    "print(train_data[0])\n",
    "print(train_data[1])\n",
    "print(train_data[2])\n",
    "print(len(test_data))\n",
    "print(test_data[0])\n",
    "\n",
    "# create vocabulary\n",
    "vocab = set()\n",
    "for document, label in train_data:\n",
    "    for word in document.split():\n",
    "        vocab.add(word.lower())\n",
    "vocab = list(vocab)\n",
    "vocab.append('<PAD>')\n",
    "vocab.append('<UNK>')\n",
    "print(len(vocab))\n",
    "print(vocab[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max doc length : 415\n",
      "average doc length : 194.9475\n"
     ]
    }
   ],
   "source": [
    "# transform the documents into list of indices\n",
    "def transform_doc(document, vocab):\n",
    "    indices = []\n",
    "    for word in document.split():\n",
    "        if word.lower() in vocab:\n",
    "            indices.append(vocab.index(word.lower()))\n",
    "        else:\n",
    "            indices.append(vocab.index('<UNK>'))\n",
    "    return indices\n",
    "\n",
    "# do it for all the sentences\n",
    "train_data = [(transform_doc(document, vocab), label) for document, label in train_data]\n",
    "test_data = [(transform_doc(document, vocab), label) for document, label in test_data]\n",
    "# print(train_data[0])\n",
    "# print(test_data[0])\n",
    "\n",
    "# get the max length of the documents and also average length\n",
    "total_len = 0\n",
    "max_len = 0\n",
    "count = 0\n",
    "for document, label in train_data:\n",
    "    max_len = max(max_len, len(document))\n",
    "    total_len += len(document)\n",
    "    count += 1\n",
    "\n",
    "print(f'max doc length : {max_len}')\n",
    "print(f'average doc length : {total_len/count}')\n",
    "\n",
    "# pad the sentences to make them of same length\n",
    "def pad_doc(document, max_len):\n",
    "    if len(document) < max_len:\n",
    "        document += [vocab.index('<PAD>')] * (max_len - len(document))\n",
    "    return document\n",
    "\n",
    "train_data = [(pad_doc(document, max_len), label) for document, label in train_data]\n",
    "test_data = [(pad_doc(document, max_len), label) for document, label in test_data]\n",
    "# print(train_data[0])\n",
    "# print(len(train_data[0][0]))\n",
    "# print(test_data[0])\n",
    "\n",
    "# batchify the data after converting to tensors\n",
    "class Batchify(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx][0]), torch.tensor(self.data[idx][1])\n",
    "    \n",
    "train_data = Batchify(train_data)\n",
    "test_data = Batchify(test_data)\n",
    "\n",
    "# create dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m     36\u001b[0m \u001b[39m# create model\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m model \u001b[39m=\u001b[39m Transformer(\u001b[39mlen\u001b[39;49m(vocab), \u001b[39m128\u001b[39;49m, \u001b[39m8\u001b[39;49m, \u001b[39m4\u001b[39;49m, \u001b[39m0.2\u001b[39;49m, max_len)\n\u001b[1;32m     38\u001b[0m \u001b[39mprint\u001b[39m(model)\n",
      "Cell \u001b[0;32mIn[13], line 11\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[0;34m(self, vocab_size, embedding_dim, n_heads, n_layers, dropout, max_len)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(vocab_size, embedding_dim)\n\u001b[1;32m     10\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_embedding \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(max_len, embedding_dim)\n\u001b[0;32m---> 11\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mTransformer(embedding_dim, n_heads, n_layers, dropout)\n\u001b[1;32m     12\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(embedding_dim, \u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:76\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[0;34m(self, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout, activation, custom_encoder, custom_decoder, layer_norm_eps, batch_first, norm_first, device, dtype)\u001b[0m\n\u001b[1;32m     72\u001b[0m     decoder_layer \u001b[39m=\u001b[39m TransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout,\n\u001b[1;32m     73\u001b[0m                                             activation, layer_norm_eps, batch_first, norm_first,\n\u001b[1;32m     74\u001b[0m                                             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs)\n\u001b[1;32m     75\u001b[0m     decoder_norm \u001b[39m=\u001b[39m LayerNorm(d_model, eps\u001b[39m=\u001b[39mlayer_norm_eps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs)\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder \u001b[39m=\u001b[39m TransformerDecoder(decoder_layer, num_decoder_layers, decoder_norm)\n\u001b[1;32m     78\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset_parameters()\n\u001b[1;32m     80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model \u001b[39m=\u001b[39m d_model\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:310\u001b[0m, in \u001b[0;36mTransformerDecoder.__init__\u001b[0;34m(self, decoder_layer, num_layers, norm)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, decoder_layer, num_layers, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    309\u001b[0m     \u001b[39msuper\u001b[39m(TransformerDecoder, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers \u001b[39m=\u001b[39m _get_clones(decoder_layer, num_layers)\n\u001b[1;32m    311\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers \u001b[39m=\u001b[39m num_layers\n\u001b[1;32m    312\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39m=\u001b[39m norm\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:682\u001b[0m, in \u001b[0;36m_get_clones\u001b[0;34m(module, N)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_clones\u001b[39m(module, N):\n\u001b[0;32m--> 682\u001b[0m     \u001b[39mreturn\u001b[39;00m ModuleList([copy\u001b[39m.\u001b[39mdeepcopy(module) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(N)])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# every document has a label : 1 or 2 or 3\n",
    "# we need a model that can take a document and predict the label and implement it using transformer (basically textual coherence)\n",
    "\n",
    "# transformer model\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_heads, n_layers, dropout, max_len):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_len, embedding_dim)\n",
    "        self.transformer = nn.Transformer(embedding_dim, n_heads, n_layers, dropout)\n",
    "        self.fc = nn.Linear(embedding_dim, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x : (batch_size, seq_len)\n",
    "        batch_size = x.shape[0]\n",
    "        seq_len = x.shape[1]\n",
    "        x = self.embedding(x)\n",
    "        # x : (batch_size, seq_len, embedding_dim)\n",
    "        pos = torch.arange(0, seq_len).unsqueeze(0).repeat(batch_size, 1)\n",
    "        # pos : (batch_size, seq_len)\n",
    "        x = x + self.pos_embedding(pos)\n",
    "        # x : (batch_size, seq_len, embedding_dim)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        # x : (seq_len, batch_size, embedding_dim)\n",
    "        x = self.transformer(x)\n",
    "        # x : (seq_len, batch_size, embedding_dim)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        # x : (batch_size, seq_len, embedding_dim)\n",
    "        x = self.fc(x)\n",
    "        # x : (batch_size, seq_len, 3)\n",
    "        x = x[:, -1, :]\n",
    "        # x : (batch_size, 3)\n",
    "        return x\n",
    "    \n",
    "# create model\n",
    "model = Transformer(len(vocab), 128, 8, 4, 0.2, max_len)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
