{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import json\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "('two options the us views the transitional national council as the sole / only legitimate interlocutor of the libyan people during this interim period , as libyans come together to plan their own future and a permanent , inclusive constitutional system that protects the rights of all libyans . <eos> this is in contrast to the qadhafi regime , which has lost all legitimacy to rule . <eos> the us views the transitional national council as the legitimate interlocutor of the libyan people during this interim period , as libyans come together to plan their own future and a permanent , inclusive constitutional system that protects the rights of all libyans . <eos> this is in contrast to the qadhafi regime , which has lost all legitimacy to rule . <eos> the inc is the institution through which we are engaging the libyan people at this time . <eos>', 3)\n",
      "(\"ambassador , we just received an email from the adoption service provider about these cases . <eos> i am currently reviewing the files to determine if they qualify within the guidelines established recently by uscis and dos . <eos> out of the 60 cases , 40 are being adopted by usc . <eos> out of the 40 , 5 of the cases were children escorted today and per cnn have just landed in miami . <eos> the remaining 35 we are reviewing now . <eos> some correspondence i 've seen says that they plan on bringing the children straight to the airport , and we have responded that they first need to come to the embassy . <eos> once case in particular will be an issue , as it requires the presidential waiver . <eos> did you receive the talking points about presidential waivers ? <eos> the majority of the cases will qualify for humanitarian parole . <eos> in the last 30 minutes a number of emails have been coming in about private planes , ted turner offering to fly children out , etc . <eos> we have a case coming in tomorrow morning in which the 2 adoptive families are being flown in by cbs helicopter from the dr . <eos> we are preparing as many cases in advance as possible tonight . <eos> kind regards , linda <eos>\", 1)\n",
      "(\"hillary , as you have been so kind to share your advice and mentorship with me in the past , i was hoping that we might find some time to chat about some of my current thinking . <eos> with the fabulous results of the presidents ' re - election , i am privileged to be able to continue to serve at the cftc . <eos> i recall your prior advice upon my being offered the post <eos> and it was invaluable . <eos> the challenges and opportunities to bring about common sense financial reforms have been fabulous . <eos> we are now moving beyond agency rule writing and helping the swaps markets transition to a new era of transparency and oversight . <eos> ( the cftc just completed final determinations such that the us has met the pittsburgh g-20 commitment deadline of december 2012 to have our swaps clearing mandate fully in place . ) <eos> if we might be able to find a moment to chat , i would love to share my thoughts on possible new challenges and opportunities within the administration . <eos> i hope all is well with you as well as you gear up for this holiday time and a much deserved break from the day to day stresses of your current post . <eos> gary <eos>\", 2)\n",
      "200\n",
      "(\"madame secretary : thank you for reaching out to secretary solis and convincing her to join the verification commission . <eos> she and ricardo lagos will make for a very high profile and effective international component of the commission . <eos> we will meet with her this morning at 10 am to brief her for tuesday 's journey to honduras . <eos> at this point , it appears we have a military aircraft available . <eos> the plan is for the u.s. delegation to depart d.c. , stop in miami to pick up ricardo lagos , and arrive in tegucigalpa together . <eos> we think this will send a powerful message to hondurans and leave no doubt about our commitment to seeing this process through to a successful conclusion . <eos> you should be aware that ambassador hugo llorens is under public assault . <eos> the wall street journal dedicates its america 's column this morning to attacking him and calling for his removal . <eos> last friday , representative connie mack did the same . <eos> this chorus will grow as the extent of our accomplishment is understood . <eos> llorens is a tough , stalwart guy . <eos> he and his mission have held firm during this crisis . <eos> a call from you would be a big boost . <eos> finally , we will hold an ipc today to identify further steps . <eos> we will keep you up to date on these steps and identify further opportunities for your engagement . <eos> i want to thank you for your leadership and support during this long crisis . <eos> your willingness to engage at key moments and take risks at the right time have propelled us much further than anyone expected . <eos> your diplomacy prevented a debilitating civil conflict in honduras that would have destabilized central america and undermined two decades of our efforts . <eos> we now have a big opportunity in front of us , and for that we are grateful to you . <eos> regards , tom <eos>\", 3)\n",
      "11943\n",
      "['there', 'implementing', 'rebels', 'trade', 'solution', 'popped', '3/30', 'hodgepodge', 'pro', 'aircraft']\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_inp_file = 'processed_data/GCDC/Clinton_train.jsonl'\n",
    "with open(train_inp_file, 'r') as f:\n",
    "    for line in f:\n",
    "        json_obj = json.loads(line)\n",
    "        # put <EOS> at the end of each sentence and add each sentence to the list\n",
    "        for i in range(len(json_obj['sentences'])):\n",
    "            json_obj['sentences'][i].append('<EOS>')\n",
    "        # merge all sentences into one\n",
    "        document = \" \".join([word for sentence in json_obj['sentences'] for word in sentence])\n",
    "        document = document.lower()\n",
    "        label = json_obj['label']\n",
    "        train_data.append((document, label))\n",
    "   \n",
    "\n",
    "test_data = []\n",
    "test_inp_file = 'processed_data/GCDC/Clinton_test.jsonl'\n",
    "with open(test_inp_file, 'r') as f:\n",
    "    for line in f:\n",
    "        json_obj = json.loads(line)\n",
    "        # put <EOS> at the end of each sentence and add each sentence to the list\n",
    "        for i in range(len(json_obj['sentences'])):\n",
    "            json_obj['sentences'][i].append('<EOS>')\n",
    "        # merge all sentences into one\n",
    "        document = \" \".join([word for sentence in json_obj['sentences'] for word in sentence])\n",
    "        document = document.lower()\n",
    "        label = json_obj['label']\n",
    "        test_data.append((document, label))\n",
    "        \n",
    "print(len(train_data))\n",
    "print(train_data[0])\n",
    "print(train_data[1])\n",
    "print(train_data[2])\n",
    "print(len(test_data))\n",
    "print(test_data[0])\n",
    "\n",
    "# create vocabulary\n",
    "vocab = set()\n",
    "for document, label in train_data:\n",
    "    for word in document.split():\n",
    "        vocab.add(word.lower())\n",
    "vocab = list(vocab)\n",
    "vocab.append('<PAD>')\n",
    "vocab.append('<UNK>')\n",
    "print(len(vocab))\n",
    "print(vocab[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max doc length : 415\n",
      "average doc length : 194.9475\n"
     ]
    }
   ],
   "source": [
    "# transform the documents into list of indices\n",
    "def transform_doc(document, vocab):\n",
    "    indices = []\n",
    "    for word in document.split():\n",
    "        if word.lower() in vocab:\n",
    "            indices.append(vocab.index(word.lower()))\n",
    "        else:\n",
    "            indices.append(vocab.index('<UNK>'))\n",
    "    return indices\n",
    "\n",
    "# do it for all the sentences\n",
    "train_data = [(transform_doc(document, vocab), label) for document, label in train_data]\n",
    "test_data = [(transform_doc(document, vocab), label) for document, label in test_data]\n",
    "# print(train_data[0])\n",
    "# print(test_data[0])\n",
    "\n",
    "# get the max length of the documents and also average length\n",
    "total_len = 0\n",
    "max_len = 0\n",
    "count = 0\n",
    "for document, label in train_data:\n",
    "    max_len = max(max_len, len(document))\n",
    "    total_len += len(document)\n",
    "    count += 1\n",
    "\n",
    "print(f'max doc length : {max_len}')\n",
    "print(f'average doc length : {total_len/count}')\n",
    "\n",
    "# pad the sentences to make them of same length\n",
    "def pad_doc(document, max_len):\n",
    "    if len(document) < max_len:\n",
    "        document += [vocab.index('<PAD>')] * (max_len - len(document))\n",
    "    return document\n",
    "\n",
    "train_data = [(pad_doc(document, max_len), label) for document, label in train_data]\n",
    "test_data = [(pad_doc(document, max_len), label) for document, label in test_data]\n",
    "# print(train_data[0])\n",
    "# print(len(train_data[0][0]))\n",
    "# print(test_data[0])\n",
    "\n",
    "# batchify the data after converting to tensors\n",
    "class Batchify(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx][0]), torch.tensor(self.data[idx][1])\n",
    "    \n",
    "train_data = Batchify(train_data)\n",
    "test_data = Batchify(test_data)\n",
    "\n",
    "# create dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.5, inplace=False)\n",
      "        (dropout2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.5, inplace=False)\n",
      "        (dropout2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder): Embedding(11943, 128)\n",
      "  (decoder): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        try:\n",
    "            from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        except:\n",
    "            raise ImportError('TransformerEncoder module does not exist in PyTorch 1.1 or lower.')\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(nhid, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(nhid, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(vocab_size, nhid)\n",
    "        self.nhid = nhid\n",
    "        self.decoder = nn.Linear(nhid, 3)\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "        src = self.encoder(src) * math.sqrt(self.nhid)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return F.log_softmax(output, dim=-1)\n",
    "        # return output\n",
    "    \n",
    "\n",
    "model = TransformerModel(len(vocab), 2, 128, 2)\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n",
      "data shape : torch.Size([32, 415])\n",
      "target shape : torch.Size([32])\n",
      "output shape : torch.Size([32, 415, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[32, 1, 3]' is invalid for input of size 32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m11\u001b[39m):\n\u001b[1;32m     41\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, train_loader, criterion, optimizer, device)\n\u001b[0;32m---> 42\u001b[0m     test_loss, test_acc \u001b[39m=\u001b[39m test(model, test_loader, criterion, device)\n\u001b[1;32m     43\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch : \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, Train Loss : \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m}\u001b[39;00m\u001b[39m, Test Loss : \u001b[39m\u001b[39m{\u001b[39;00mtest_loss\u001b[39m}\u001b[39;00m\u001b[39m, Test Accuracy : \u001b[39m\u001b[39m{\u001b[39;00mtest_acc\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[39m# save the model\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 36\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, test_loader, criterion, device)\u001b[0m\n\u001b[1;32m     34\u001b[0m         total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     35\u001b[0m         pred \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 36\u001b[0m         correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39meq(target\u001b[39m.\u001b[39;49mview_as(pred))\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     37\u001b[0m \u001b[39mreturn\u001b[39;00m total_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(test_loader), correct \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(test_loader\u001b[39m.\u001b[39mdataset)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[32, 1, 3]' is invalid for input of size 32"
     ]
    }
   ],
   "source": [
    "# define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train the model\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        print(f'data shape : {data.shape}')\n",
    "        target = target.to(device)\n",
    "        print(f'target shape : {target.shape}')\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        print(f'output shape : {output.shape}')\n",
    "        # loss = criterion(output.view(32, -1), target.view(-1))\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# test the model\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            # loss = criterion(output.view(32, -1), target.view(-1))\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return total_loss / len(test_loader), correct / len(test_loader.dataset)\n",
    "\n",
    "# train and test the model\n",
    "for epoch in range(1, 11):\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = test(model, test_loader, criterion, device)\n",
    "    print(f'Epoch : {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}, Test Accuracy : {test_acc}')\n",
    "\n",
    "# save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
