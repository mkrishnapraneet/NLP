{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "from nltk import word_tokenize\n",
    "import torchtext\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "batch_size = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "('two options the us views the transitional national council as the sole / only legitimate interlocutor of the libyan people during this interim period , as libyans come together to plan their own future and a permanent , inclusive constitutional system that protects the rights of all libyans . <eos> this is in contrast to the qadhafi regime , which has lost all legitimacy to rule . <eos> the us views the transitional national council as the legitimate interlocutor of the libyan people during this interim period , as libyans come together to plan their own future and a permanent , inclusive constitutional system that protects the rights of all libyans . <eos> this is in contrast to the qadhafi regime , which has lost all legitimacy to rule . <eos> the inc is the institution through which we are engaging the libyan people at this time . <eos>', 2)\n",
      "(\"ambassador , we just received an email from the adoption service provider about these cases . <eos> i am currently reviewing the files to determine if they qualify within the guidelines established recently by uscis and dos . <eos> out of the 60 cases , 40 are being adopted by usc . <eos> out of the 40 , 5 of the cases were children escorted today and per cnn have just landed in miami . <eos> the remaining 35 we are reviewing now . <eos> some correspondence i 've seen says that they plan on bringing the children straight to the airport , and we have responded that they first need to come to the embassy . <eos> once case in particular will be an issue , as it requires the presidential waiver . <eos> did you receive the talking points about presidential waivers ? <eos> the majority of the cases will qualify for humanitarian parole . <eos> in the last 30 minutes a number of emails have been coming in about private planes , ted turner offering to fly children out , etc . <eos> we have a case coming in tomorrow morning in which the 2 adoptive families are being flown in by cbs helicopter from the dr . <eos> we are preparing as many cases in advance as possible tonight . <eos> kind regards , linda <eos>\", 0)\n",
      "(\"hillary , as you have been so kind to share your advice and mentorship with me in the past , i was hoping that we might find some time to chat about some of my current thinking . <eos> with the fabulous results of the presidents ' re - election , i am privileged to be able to continue to serve at the cftc . <eos> i recall your prior advice upon my being offered the post <eos> and it was invaluable . <eos> the challenges and opportunities to bring about common sense financial reforms have been fabulous . <eos> we are now moving beyond agency rule writing and helping the swaps markets transition to a new era of transparency and oversight . <eos> ( the cftc just completed final determinations such that the us has met the pittsburgh g-20 commitment deadline of december 2012 to have our swaps clearing mandate fully in place . ) <eos> if we might be able to find a moment to chat , i would love to share my thoughts on possible new challenges and opportunities within the administration . <eos> i hope all is well with you as well as you gear up for this holiday time and a much deserved break from the day to day stresses of your current post . <eos> gary <eos>\", 1)\n",
      "200\n",
      "(\"madame secretary : thank you for reaching out to secretary solis and convincing her to join the verification commission . <eos> she and ricardo lagos will make for a very high profile and effective international component of the commission . <eos> we will meet with her this morning at 10 am to brief her for tuesday 's journey to honduras . <eos> at this point , it appears we have a military aircraft available . <eos> the plan is for the u.s. delegation to depart d.c. , stop in miami to pick up ricardo lagos , and arrive in tegucigalpa together . <eos> we think this will send a powerful message to hondurans and leave no doubt about our commitment to seeing this process through to a successful conclusion . <eos> you should be aware that ambassador hugo llorens is under public assault . <eos> the wall street journal dedicates its america 's column this morning to attacking him and calling for his removal . <eos> last friday , representative connie mack did the same . <eos> this chorus will grow as the extent of our accomplishment is understood . <eos> llorens is a tough , stalwart guy . <eos> he and his mission have held firm during this crisis . <eos> a call from you would be a big boost . <eos> finally , we will hold an ipc today to identify further steps . <eos> we will keep you up to date on these steps and identify further opportunities for your engagement . <eos> i want to thank you for your leadership and support during this long crisis . <eos> your willingness to engage at key moments and take risks at the right time have propelled us much further than anyone expected . <eos> your diplomacy prevented a debilitating civil conflict in honduras that would have destabilized central america and undermined two decades of our efforts . <eos> we now have a big opportunity in front of us , and for that we are grateful to you . <eos> regards , tom <eos>\", 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_inp_file = 'processed_data/GCDC/Clinton_train.jsonl'\n",
    "with open(train_inp_file, 'r') as f:\n",
    "    for line in f:\n",
    "        json_obj = json.loads(line)\n",
    "        # put <EOS> at the end of each sentence and add each sentence to the list\n",
    "        for i in range(len(json_obj['sentences'])):\n",
    "            json_obj['sentences'][i].append('<EOS>')\n",
    "        # merge all sentences into one\n",
    "        document = \" \".join([word for sentence in json_obj['sentences'] for word in sentence])\n",
    "        document = document.lower()\n",
    "        label = json_obj['label']\n",
    "        train_data.append((document, label-1))\n",
    "   \n",
    "\n",
    "test_data = []\n",
    "test_inp_file = 'processed_data/GCDC/Clinton_test.jsonl'\n",
    "with open(test_inp_file, 'r') as f:\n",
    "    for line in f:\n",
    "        json_obj = json.loads(line)\n",
    "        # put <EOS> at the end of each sentence and add each sentence to the list\n",
    "        for i in range(len(json_obj['sentences'])):\n",
    "            json_obj['sentences'][i].append('<EOS>')\n",
    "        # merge all sentences into one\n",
    "        document = \" \".join([word for sentence in json_obj['sentences'] for word in sentence])\n",
    "        document = document.lower()\n",
    "        label = json_obj['label']\n",
    "        test_data.append((document, label-1))\n",
    "        \n",
    "print(len(train_data))\n",
    "print(train_data[0])\n",
    "print(train_data[1])\n",
    "print(train_data[2])\n",
    "print(len(test_data))\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "print(tokenizer.vocab_size)\n",
    "print(bert.config.hidden_size)\n",
    "\n",
    "max_pad_len = 512\n",
    "pad_id = 0\n",
    "\n",
    "class GCDCDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        document, label = self.data[idx]\n",
    "        tokenized_document = self.tokenizer.tokenize(document)\n",
    "        indexed_document = self.tokenizer.convert_tokens_to_ids(tokenized_document)\n",
    "        indexed_document = indexed_document[:max_pad_len]\n",
    "        indexed_document = indexed_document + [pad_id] * (max_pad_len - len(indexed_document))\n",
    "        return torch.tensor(indexed_document), torch.tensor(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "200\n",
      "(tensor([ 2048,  7047,  1996,  2149,  5328,  1996, 17459,  2120,  2473,  2004,\n",
      "         1996,  7082,  1013,  2069, 11476,  6970,  4135, 12690,  2953,  1997,\n",
      "         1996, 19232,  2111,  2076,  2023,  9455,  2558,  1010,  2004, 19232,\n",
      "         2015,  2272,  2362,  2000,  2933,  2037,  2219,  2925,  1998,  1037,\n",
      "         4568,  1010, 18678,  6543,  2291,  2008, 18227,  1996,  2916,  1997,\n",
      "         2035, 19232,  2015,  1012,  1026,  1041,  2891,  1028,  2023,  2003,\n",
      "         1999,  5688,  2000,  1996,  1053,  4215,  3270,  8873,  6939,  1010,\n",
      "         2029,  2038,  2439,  2035, 22568,  2000,  3627,  1012,  1026,  1041,\n",
      "         2891,  1028,  1996,  2149,  5328,  1996, 17459,  2120,  2473,  2004,\n",
      "         1996, 11476,  6970,  4135, 12690,  2953,  1997,  1996, 19232,  2111,\n",
      "         2076,  2023,  9455,  2558,  1010,  2004, 19232,  2015,  2272,  2362,\n",
      "         2000,  2933,  2037,  2219,  2925,  1998,  1037,  4568,  1010, 18678,\n",
      "         6543,  2291,  2008, 18227,  1996,  2916,  1997,  2035, 19232,  2015,\n",
      "         1012,  1026,  1041,  2891,  1028,  2023,  2003,  1999,  5688,  2000,\n",
      "         1996,  1053,  4215,  3270,  8873,  6939,  1010,  2029,  2038,  2439,\n",
      "         2035, 22568,  2000,  3627,  1012,  1026,  1041,  2891,  1028,  1996,\n",
      "         4297,  2003,  1996,  5145,  2083,  2029,  2057,  2024, 11973,  1996,\n",
      "        19232,  2111,  2012,  2023,  2051,  1012,  1026,  1041,  2891,  1028,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]), tensor(2))\n",
      "(tensor([10602,  3187,  1024,  4067,  2017,  2005,  4285,  2041,  2000,  3187,\n",
      "        14017,  2483,  1998, 13359,  2014,  2000,  3693,  1996, 22616,  3222,\n",
      "         1012,  1026,  1041,  2891,  1028,  2016,  1998, 13559, 16738,  2097,\n",
      "         2191,  2005,  1037,  2200,  2152,  6337,  1998,  4621,  2248,  6922,\n",
      "         1997,  1996,  3222,  1012,  1026,  1041,  2891,  1028,  2057,  2097,\n",
      "         3113,  2007,  2014,  2023,  2851,  2012,  2184,  2572,  2000,  4766,\n",
      "         2014,  2005,  9857,  1005,  1055,  4990,  2000, 14373,  1012,  1026,\n",
      "         1041,  2891,  1028,  2012,  2023,  2391,  1010,  2009,  3544,  2057,\n",
      "         2031,  1037,  2510,  2948,  2800,  1012,  1026,  1041,  2891,  1028,\n",
      "         1996,  2933,  2003,  2005,  1996,  1057,  1012,  1055,  1012, 10656,\n",
      "         2000, 18280,  1040,  1012,  1039,  1012,  1010,  2644,  1999,  5631,\n",
      "         2000,  4060,  2039, 13559, 16738,  1010,  1998,  7180,  1999,  8915,\n",
      "        12193,  6895,  9692,  4502,  2362,  1012,  1026,  1041,  2891,  1028,\n",
      "         2057,  2228,  2023,  2097,  4604,  1037,  3928,  4471,  2000, 10189,\n",
      "        24979,  6962,  1998,  2681,  2053,  4797,  2055,  2256,  8426,  2000,\n",
      "         3773,  2023,  2832,  2083,  2000,  1037,  3144,  7091,  1012,  1026,\n",
      "         1041,  2891,  1028,  2017,  2323,  2022,  5204,  2008,  6059,  9395,\n",
      "         2222,  5686,  3619,  2003,  2104,  2270,  6101,  1012,  1026,  1041,\n",
      "         2891,  1028,  1996,  2813,  2395,  3485,  2139, 16467,  2015,  2049,\n",
      "         2637,  1005,  1055,  5930,  2023,  2851,  2000,  7866,  2032,  1998,\n",
      "         4214,  2005,  2010,  8208,  1012,  1026,  1041,  2891,  1028,  2197,\n",
      "         5958,  1010,  4387, 16560, 11349,  2106,  1996,  2168,  1012,  1026,\n",
      "         1041,  2891,  1028,  2023,  7165,  2097,  4982,  2004,  1996,  6698,\n",
      "         1997,  2256, 24718,  2003,  5319,  1012,  1026,  1041,  2891,  1028,\n",
      "         2222,  5686,  3619,  2003,  1037,  7823,  1010,  2358,  2389, 18367,\n",
      "         3124,  1012,  1026,  1041,  2891,  1028,  2002,  1998,  2010,  3260,\n",
      "         2031,  2218,  3813,  2076,  2023,  5325,  1012,  1026,  1041,  2891,\n",
      "         1028,  1037,  2655,  2013,  2017,  2052,  2022,  1037,  2502, 12992,\n",
      "         1012,  1026,  1041,  2891,  1028,  2633,  1010,  2057,  2097,  2907,\n",
      "         2019, 12997,  2278,  2651,  2000,  6709,  2582,  4084,  1012,  1026,\n",
      "         1041,  2891,  1028,  2057,  2097,  2562,  2017,  2039,  2000,  3058,\n",
      "         2006,  2122,  4084,  1998,  6709,  2582,  6695,  2005,  2115,  8147,\n",
      "         1012,  1026,  1041,  2891,  1028,  1045,  2215,  2000,  4067,  2017,\n",
      "         2005,  2115,  4105,  1998,  2490,  2076,  2023,  2146,  5325,  1012,\n",
      "         1026,  1041,  2891,  1028,  2115, 19732,  2000,  8526,  2012,  3145,\n",
      "         5312,  1998,  2202, 10831,  2012,  1996,  2157,  2051,  2031, 15801,\n",
      "         2149,  2172,  2582,  2084,  3087,  3517,  1012,  1026,  1041,  2891,\n",
      "         1028,  2115, 17610,  8729,  1037,  2139, 14454, 16518,  2942,  4736,\n",
      "         1999, 14373,  2008,  2052,  2031,  4078,  2696, 14454,  3550,  2430,\n",
      "         2637,  1998, 25174,  2094,  2048,  5109,  1997,  2256,  4073,  1012,\n",
      "         1026,  1041,  2891,  1028,  2057,  2085,  2031,  1037,  2502,  4495,\n",
      "         1999,  2392,  1997,  2149,  1010,  1998,  2005,  2008,  2057,  2024,\n",
      "         8794,  2000,  2017,  1012,  1026,  1041,  2891,  1028, 12362,  1010,\n",
      "         3419,  1026,  1041,  2891,  1028,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]), tensor(2))\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "train_dataset = GCDCDataset(train_data, tokenizer)\n",
    "test_dataset = GCDCDataset(test_data, tokenizer)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(train_dataset[0])\n",
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a classifier\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.linear = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "# define a transformer model\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.classifier = Classifier(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len)\n",
    "        # output: (batch_size, hidden_size)\n",
    "        output = self.bert(x)[0][:, 0, :]\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to train the model\n",
    "def train(model, optimizer, criterion, train_loader, test_loader, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for document, label in train_loader:\n",
    "            # document: (batch_size, seq_len)\n",
    "            # label: (batch_size)\n",
    "            document = document.to(device)\n",
    "            label = label.to(device)\n",
    "            # output: (batch_size, num_classes)\n",
    "            output = model(document)\n",
    "            # output: (batch_size, num_classes)\n",
    "            loss = criterion(output, label)\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('Epoch: {}, Loss: {}'.format(epoch, loss.item()))\n",
    "        test(model, test_loader)\n",
    "\n",
    "# define a function to test the model\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for document, label in test_loader:\n",
    "            # document: (batch_size, seq_len)\n",
    "            # label: (batch_size)\n",
    "            document = document.to(device)\n",
    "            label = label.to(device)\n",
    "            # output: (batch_size, num_classes)\n",
    "            output = model(document)\n",
    "            # output: (batch_size)\n",
    "            output = torch.argmax(output, dim=1)\n",
    "            correct += torch.sum(torch.eq(output, label)).item()\n",
    "            total += len(label)\n",
    "    print('Accuracy: {}'.format(correct / total))\n",
    "\n",
    "# define a function to predict the label of a document\n",
    "def predict(model, document):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # document: (seq_len)\n",
    "        document = torch.LongTensor(document).unsqueeze(0).to(device)\n",
    "        # output: (1, num_classes)\n",
    "        output = model(document)\n",
    "        # output: (1)\n",
    "        output = torch.argmax(output, dim=1)\n",
    "        return output.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a transformer model\n",
    "hidden_size = bert.config.hidden_size\n",
    "num_classes = 3\n",
    "model = Transformer(hidden_size, num_classes).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 5.80 GiB total capacity; 514.99 MiB already allocated; 13.44 MiB free; 568.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# train the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m----> 3\u001b[0m train(model, optimizer, criterion, train_loader, test_loader, num_epochs)\n",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, train_loader, test_loader, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m \u001b[39m# output: (batch_size, num_classes)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m output \u001b[39m=\u001b[39m model(document)\n\u001b[1;32m     12\u001b[0m \u001b[39m# output: (batch_size, num_classes)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, label)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     18\u001b[0m     \u001b[39m# x: (batch_size, seq_len)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[39m# output: (batch_size, hidden_size)\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(x)[\u001b[39m0\u001b[39m][:, \u001b[39m0\u001b[39m, :]\n\u001b[1;32m     21\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(output)\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1013\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[1;32m   1014\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1015\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1016\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1017\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1018\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[1;32m   1019\u001b[0m )\n\u001b[1;32m   1020\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[1;32m   1021\u001b[0m     embedding_output,\n\u001b[1;32m   1022\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m   1031\u001b[0m )\n\u001b[1;32m   1032\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:233\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    230\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_embeddings(input_ids)\n\u001b[1;32m    231\u001b[0m token_type_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[0;32m--> 233\u001b[0m embeddings \u001b[39m=\u001b[39m inputs_embeds \u001b[39m+\u001b[39;49m token_type_embeddings\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabsolute\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    235\u001b[0m     position_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embeddings(position_ids)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 5.80 GiB total capacity; 514.99 MiB already allocated; 13.44 MiB free; 568.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "num_epochs = 10\n",
    "train(model, optimizer, criterion, train_loader, test_loader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
