{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "from nltk import word_tokenize\n",
    "import torchtext\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import BertConfig, BertForSequenceClassification\n",
    "\n",
    "batch_size = 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "('two options the us views the transitional national council as the sole / only legitimate interlocutor of the libyan people during this interim period , as libyans come together to plan their own future and a permanent , inclusive constitutional system that protects the rights of all libyans . <eos> this is in contrast to the qadhafi regime , which has lost all legitimacy to rule . <eos> the us views the transitional national council as the legitimate interlocutor of the libyan people during this interim period , as libyans come together to plan their own future and a permanent , inclusive constitutional system that protects the rights of all libyans . <eos> this is in contrast to the qadhafi regime , which has lost all legitimacy to rule . <eos> the inc is the institution through which we are engaging the libyan people at this time . <eos>', 2)\n",
      "(\"ambassador , we just received an email from the adoption service provider about these cases . <eos> i am currently reviewing the files to determine if they qualify within the guidelines established recently by uscis and dos . <eos> out of the 60 cases , 40 are being adopted by usc . <eos> out of the 40 , 5 of the cases were children escorted today and per cnn have just landed in miami . <eos> the remaining 35 we are reviewing now . <eos> some correspondence i 've seen says that they plan on bringing the children straight to the airport , and we have responded that they first need to come to the embassy . <eos> once case in particular will be an issue , as it requires the presidential waiver . <eos> did you receive the talking points about presidential waivers ? <eos> the majority of the cases will qualify for humanitarian parole . <eos> in the last 30 minutes a number of emails have been coming in about private planes , ted turner offering to fly children out , etc . <eos> we have a case coming in tomorrow morning in which the 2 adoptive families are being flown in by cbs helicopter from the dr . <eos> we are preparing as many cases in advance as possible tonight . <eos> kind regards , linda <eos>\", 0)\n",
      "(\"hillary , as you have been so kind to share your advice and mentorship with me in the past , i was hoping that we might find some time to chat about some of my current thinking . <eos> with the fabulous results of the presidents ' re - election , i am privileged to be able to continue to serve at the cftc . <eos> i recall your prior advice upon my being offered the post <eos> and it was invaluable . <eos> the challenges and opportunities to bring about common sense financial reforms have been fabulous . <eos> we are now moving beyond agency rule writing and helping the swaps markets transition to a new era of transparency and oversight . <eos> ( the cftc just completed final determinations such that the us has met the pittsburgh g-20 commitment deadline of december 2012 to have our swaps clearing mandate fully in place . ) <eos> if we might be able to find a moment to chat , i would love to share my thoughts on possible new challenges and opportunities within the administration . <eos> i hope all is well with you as well as you gear up for this holiday time and a much deserved break from the day to day stresses of your current post . <eos> gary <eos>\", 1)\n",
      "200\n",
      "(\"madame secretary : thank you for reaching out to secretary solis and convincing her to join the verification commission . <eos> she and ricardo lagos will make for a very high profile and effective international component of the commission . <eos> we will meet with her this morning at 10 am to brief her for tuesday 's journey to honduras . <eos> at this point , it appears we have a military aircraft available . <eos> the plan is for the u.s. delegation to depart d.c. , stop in miami to pick up ricardo lagos , and arrive in tegucigalpa together . <eos> we think this will send a powerful message to hondurans and leave no doubt about our commitment to seeing this process through to a successful conclusion . <eos> you should be aware that ambassador hugo llorens is under public assault . <eos> the wall street journal dedicates its america 's column this morning to attacking him and calling for his removal . <eos> last friday , representative connie mack did the same . <eos> this chorus will grow as the extent of our accomplishment is understood . <eos> llorens is a tough , stalwart guy . <eos> he and his mission have held firm during this crisis . <eos> a call from you would be a big boost . <eos> finally , we will hold an ipc today to identify further steps . <eos> we will keep you up to date on these steps and identify further opportunities for your engagement . <eos> i want to thank you for your leadership and support during this long crisis . <eos> your willingness to engage at key moments and take risks at the right time have propelled us much further than anyone expected . <eos> your diplomacy prevented a debilitating civil conflict in honduras that would have destabilized central america and undermined two decades of our efforts . <eos> we now have a big opportunity in front of us , and for that we are grateful to you . <eos> regards , tom <eos>\", 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_inp_file = 'processed_data/GCDC/Clinton_train.jsonl'\n",
    "with open(train_inp_file, 'r') as f:\n",
    "    for line in f:\n",
    "        json_obj = json.loads(line)\n",
    "        # put <EOS> at the end of each sentence and add each sentence to the list\n",
    "        for i in range(len(json_obj['sentences'])):\n",
    "            json_obj['sentences'][i].append('<EOS>')\n",
    "        # merge all sentences into one\n",
    "        document = \" \".join([word for sentence in json_obj['sentences'] for word in sentence])\n",
    "        document = document.lower()\n",
    "        label = json_obj['label']\n",
    "        train_data.append((document, label-1))\n",
    "   \n",
    "\n",
    "test_data = []\n",
    "test_inp_file = 'processed_data/GCDC/Clinton_test.jsonl'\n",
    "with open(test_inp_file, 'r') as f:\n",
    "    for line in f:\n",
    "        json_obj = json.loads(line)\n",
    "        # put <EOS> at the end of each sentence and add each sentence to the list\n",
    "        for i in range(len(json_obj['sentences'])):\n",
    "            json_obj['sentences'][i].append('<EOS>')\n",
    "        # merge all sentences into one\n",
    "        document = \" \".join([word for sentence in json_obj['sentences'] for word in sentence])\n",
    "        document = document.lower()\n",
    "        label = json_obj['label']\n",
    "        test_data.append((document, label-1))\n",
    "        \n",
    "print(len(train_data))\n",
    "print(train_data[0])\n",
    "print(train_data[1])\n",
    "print(train_data[2])\n",
    "print(len(test_data))\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load the configuration of 'BertConfig {\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.27.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'BertConfig {\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.27.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n' is the correct path to a directory containing a config.json file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:628\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[39m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m    629\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    630\u001b[0m         configuration_file,\n\u001b[1;32m    631\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    632\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    633\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    634\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    635\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    636\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    637\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    638\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    639\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    640\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m    641\u001b[0m     )\n\u001b[1;32m    642\u001b[0m     commit_hash \u001b[39m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/hub.py:409\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    410\u001b[0m         path_or_repo_id,\n\u001b[1;32m    411\u001b[0m         filename,\n\u001b[1;32m    412\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    413\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    414\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    415\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    416\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    417\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    418\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    419\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    420\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    421\u001b[0m     )\n\u001b[1;32m    423\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrepo_id\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 114\u001b[0m     validate_repo_id(arg_value)\n\u001b[1;32m    116\u001b[0m \u001b[39melif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m arg_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:172\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m REPO_ID_REGEX\u001b[39m.\u001b[39mmatch(repo_id):\n\u001b[0;32m--> 172\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    173\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must use alphanumeric chars or \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m forbidden, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m cannot start or end the name, max length is 96:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    178\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m--\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m repo_id \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m..\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m repo_id:\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: 'BertConfig {\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.27.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m# bert = BertModel.from_pretrained('bert-base-uncased')\u001b[39;00m\n\u001b[1;32m      3\u001b[0m config \u001b[39m=\u001b[39m BertConfig\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mbert-base-uncased\u001b[39m\u001b[39m'\u001b[39m, num_labels\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m bert \u001b[39m=\u001b[39m BertForSequenceClassification\u001b[39m.\u001b[39;49mfrom_pretrained(config)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(tokenizer\u001b[39m.\u001b[39mvocab_size)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(bert\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mhidden_size)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:2175\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2173\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   2174\u001b[0m     config_path \u001b[39m=\u001b[39m config \u001b[39mif\u001b[39;00m config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m pretrained_model_name_or_path\n\u001b[0;32m-> 2175\u001b[0m     config, model_kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m   2176\u001b[0m         config_path,\n\u001b[1;32m   2177\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2178\u001b[0m         return_unused_kwargs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2179\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   2180\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   2181\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   2182\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   2183\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   2184\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   2185\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   2186\u001b[0m         _from_auto\u001b[39m=\u001b[39;49mfrom_auto_class,\n\u001b[1;32m   2187\u001b[0m         _from_pipeline\u001b[39m=\u001b[39;49mfrom_pipeline,\n\u001b[1;32m   2188\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2189\u001b[0m     )\n\u001b[1;32m   2190\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2191\u001b[0m     model_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:546\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    469\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_pretrained\u001b[39m(\u001b[39mcls\u001b[39m, pretrained_model_name_or_path: Union[\u001b[39mstr\u001b[39m, os\u001b[39m.\u001b[39mPathLike], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPretrainedConfig\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    470\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m    Instantiate a [`PretrainedConfig`] (or a derived class) from a pretrained model configuration.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[39m    assert unused_kwargs == {\"foo\": False}\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[39m    ```\"\"\"\u001b[39;00m\n\u001b[0;32m--> 546\u001b[0m     config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    547\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmodel_type:\n\u001b[1;32m    548\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    549\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou are using a model of type \u001b[39m\u001b[39m{\u001b[39;00mconfig_dict[\u001b[39m'\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m to instantiate a model of type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    550\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmodel_type\u001b[39m}\u001b[39;00m\u001b[39m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    551\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:573\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    572\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 573\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    574\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n\u001b[1;32m    575\u001b[0m     original_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:649\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    647\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    648\u001b[0m         \u001b[39m# For any other exception, we throw a generic error.\u001b[39;00m\n\u001b[0;32m--> 649\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    650\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load the configuration of \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. If you were trying to load it\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    651\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m from \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, make sure you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have a local directory with the same\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    652\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m name. Otherwise, make sure \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is the correct path to a directory\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    653\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m containing a \u001b[39m\u001b[39m{\u001b[39;00mconfiguration_file\u001b[39m}\u001b[39;00m\u001b[39m file\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    654\u001b[0m         )\n\u001b[1;32m    656\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    657\u001b[0m     \u001b[39m# Load config dict\u001b[39;00m\n\u001b[1;32m    658\u001b[0m     config_dict \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_dict_from_json_file(resolved_config_file)\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load the configuration of 'BertConfig {\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.27.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'BertConfig {\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.27.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n' is the correct path to a directory containing a config.json file"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "bert = BertForSequenceClassification.from_pretrained(config)\n",
    "\n",
    "print(tokenizer.vocab_size)\n",
    "print(bert.config.hidden_size)\n",
    "\n",
    "max_pad_len = 300\n",
    "pad_id = 0\n",
    "\n",
    "class GCDCDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        document, label = self.data[idx]\n",
    "        tokenized_document = self.tokenizer.tokenize(document)\n",
    "        indexed_document = self.tokenizer.convert_tokens_to_ids(tokenized_document)\n",
    "        indexed_document = indexed_document[:max_pad_len]\n",
    "        indexed_document = indexed_document + [pad_id] * (max_pad_len - len(indexed_document))\n",
    "        return torch.tensor(indexed_document), torch.tensor(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "200\n",
      "(tensor([ 2048,  7047,  1996,  2149,  5328,  1996, 17459,  2120,  2473,  2004,\n",
      "         1996,  7082,  1013,  2069, 11476,  6970,  4135, 12690,  2953,  1997,\n",
      "         1996, 19232,  2111,  2076,  2023,  9455,  2558,  1010,  2004, 19232,\n",
      "         2015,  2272,  2362,  2000,  2933,  2037,  2219,  2925,  1998,  1037,\n",
      "         4568,  1010, 18678,  6543,  2291,  2008, 18227,  1996,  2916,  1997,\n",
      "         2035, 19232,  2015,  1012,  1026,  1041,  2891,  1028,  2023,  2003,\n",
      "         1999,  5688,  2000,  1996,  1053,  4215,  3270,  8873,  6939,  1010,\n",
      "         2029,  2038,  2439,  2035, 22568,  2000,  3627,  1012,  1026,  1041,\n",
      "         2891,  1028,  1996,  2149,  5328,  1996, 17459,  2120,  2473,  2004,\n",
      "         1996, 11476,  6970,  4135, 12690,  2953,  1997,  1996, 19232,  2111,\n",
      "         2076,  2023,  9455,  2558,  1010,  2004, 19232,  2015,  2272,  2362,\n",
      "         2000,  2933,  2037,  2219,  2925,  1998,  1037,  4568,  1010, 18678,\n",
      "         6543,  2291,  2008, 18227,  1996,  2916,  1997,  2035, 19232,  2015,\n",
      "         1012,  1026,  1041,  2891,  1028,  2023,  2003,  1999,  5688,  2000,\n",
      "         1996,  1053,  4215,  3270,  8873,  6939,  1010,  2029,  2038,  2439,\n",
      "         2035, 22568,  2000,  3627,  1012,  1026,  1041,  2891,  1028,  1996,\n",
      "         4297,  2003,  1996,  5145,  2083,  2029,  2057,  2024, 11973,  1996,\n",
      "        19232,  2111,  2012,  2023,  2051,  1012,  1026,  1041,  2891,  1028,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), tensor(2))\n",
      "(tensor([10602,  3187,  1024,  4067,  2017,  2005,  4285,  2041,  2000,  3187,\n",
      "        14017,  2483,  1998, 13359,  2014,  2000,  3693,  1996, 22616,  3222,\n",
      "         1012,  1026,  1041,  2891,  1028,  2016,  1998, 13559, 16738,  2097,\n",
      "         2191,  2005,  1037,  2200,  2152,  6337,  1998,  4621,  2248,  6922,\n",
      "         1997,  1996,  3222,  1012,  1026,  1041,  2891,  1028,  2057,  2097,\n",
      "         3113,  2007,  2014,  2023,  2851,  2012,  2184,  2572,  2000,  4766,\n",
      "         2014,  2005,  9857,  1005,  1055,  4990,  2000, 14373,  1012,  1026,\n",
      "         1041,  2891,  1028,  2012,  2023,  2391,  1010,  2009,  3544,  2057,\n",
      "         2031,  1037,  2510,  2948,  2800,  1012,  1026,  1041,  2891,  1028,\n",
      "         1996,  2933,  2003,  2005,  1996,  1057,  1012,  1055,  1012, 10656,\n",
      "         2000, 18280,  1040,  1012,  1039,  1012,  1010,  2644,  1999,  5631,\n",
      "         2000,  4060,  2039, 13559, 16738,  1010,  1998,  7180,  1999,  8915,\n",
      "        12193,  6895,  9692,  4502,  2362,  1012,  1026,  1041,  2891,  1028,\n",
      "         2057,  2228,  2023,  2097,  4604,  1037,  3928,  4471,  2000, 10189,\n",
      "        24979,  6962,  1998,  2681,  2053,  4797,  2055,  2256,  8426,  2000,\n",
      "         3773,  2023,  2832,  2083,  2000,  1037,  3144,  7091,  1012,  1026,\n",
      "         1041,  2891,  1028,  2017,  2323,  2022,  5204,  2008,  6059,  9395,\n",
      "         2222,  5686,  3619,  2003,  2104,  2270,  6101,  1012,  1026,  1041,\n",
      "         2891,  1028,  1996,  2813,  2395,  3485,  2139, 16467,  2015,  2049,\n",
      "         2637,  1005,  1055,  5930,  2023,  2851,  2000,  7866,  2032,  1998,\n",
      "         4214,  2005,  2010,  8208,  1012,  1026,  1041,  2891,  1028,  2197,\n",
      "         5958,  1010,  4387, 16560, 11349,  2106,  1996,  2168,  1012,  1026,\n",
      "         1041,  2891,  1028,  2023,  7165,  2097,  4982,  2004,  1996,  6698,\n",
      "         1997,  2256, 24718,  2003,  5319,  1012,  1026,  1041,  2891,  1028,\n",
      "         2222,  5686,  3619,  2003,  1037,  7823,  1010,  2358,  2389, 18367,\n",
      "         3124,  1012,  1026,  1041,  2891,  1028,  2002,  1998,  2010,  3260,\n",
      "         2031,  2218,  3813,  2076,  2023,  5325,  1012,  1026,  1041,  2891,\n",
      "         1028,  1037,  2655,  2013,  2017,  2052,  2022,  1037,  2502, 12992,\n",
      "         1012,  1026,  1041,  2891,  1028,  2633,  1010,  2057,  2097,  2907,\n",
      "         2019, 12997,  2278,  2651,  2000,  6709,  2582,  4084,  1012,  1026]), tensor(2))\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "train_dataset = GCDCDataset(train_data, tokenizer)\n",
    "test_dataset = GCDCDataset(test_data, tokenizer)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(train_dataset[0])\n",
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a classifier\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.linear = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "# define a transformer model\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.classifier = Classifier(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len)\n",
    "        # output: (batch_size, hidden_size)\n",
    "        output = self.bert(x)[0][:, 0, :]\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to train the model\n",
    "def train(model, optimizer, criterion, train_loader, test_loader, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for document, label in train_loader:\n",
    "            # document: (batch_size, seq_len)\n",
    "            # label: (batch_size)\n",
    "            document = document.to(device)\n",
    "            label = label.to(device)\n",
    "            # output: (batch_size, num_classes)\n",
    "            output = model(document)\n",
    "            # output: (batch_size, num_classes)\n",
    "            loss = criterion(output, label)\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('Epoch: {}, Loss: {}'.format(epoch, loss.item()))\n",
    "        # test(model, test_loader)\n",
    "\n",
    "# define a function to test the model\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for document, label in test_loader:\n",
    "            # document: (batch_size, seq_len)\n",
    "            # label: (batch_size)\n",
    "            document = document.to(device)\n",
    "            label = label.to(device)\n",
    "            # output: (batch_size, num_classes)\n",
    "            output = model(document)\n",
    "            # print(output)\n",
    "            # output: (batch_size)\n",
    "            output = torch.argmax(output, dim=1)\n",
    "            correct += torch.sum(torch.eq(output, label)).item()\n",
    "            total += len(label)\n",
    "    print('Accuracy: {}'.format(correct / total))\n",
    "\n",
    "# define a function to predict the label of a document\n",
    "def predict(model, document):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # document: (seq_len)\n",
    "        document = torch.LongTensor(document).unsqueeze(0).to(device)\n",
    "        # output: (1, num_classes)\n",
    "        output = model(document)\n",
    "        # output: (1)\n",
    "        output = torch.argmax(output, dim=1)\n",
    "        return output.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a transformer model\n",
    "hidden_size = bert.config.hidden_size\n",
    "num_classes = 3\n",
    "model = Transformer(hidden_size, num_classes).to(device)\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.0586494207382202\n",
      "Epoch: 1, Loss: 1.041995882987976\n",
      "Epoch: 2, Loss: 0.9398596286773682\n",
      "Epoch: 3, Loss: 0.894568920135498\n",
      "Epoch: 4, Loss: 1.0646461248397827\n",
      "Epoch: 5, Loss: 1.0431761741638184\n",
      "Epoch: 6, Loss: 1.2892374992370605\n",
      "Epoch: 7, Loss: 1.1616665124893188\n",
      "Epoch: 8, Loss: 1.1563405990600586\n",
      "Epoch: 9, Loss: 0.7746480703353882\n",
      "Accuracy: 0.555\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "num_epochs = 10\n",
    "train(model, optimizer, criterion, train_loader, test_loader, num_epochs)\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0  51]\n",
      " [  0   0  38]\n",
      " [  0   0 111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        51\n",
      "           1       0.00      0.00      0.00        38\n",
      "           2       0.56      1.00      0.71       111\n",
      "\n",
      "    accuracy                           0.56       200\n",
      "   macro avg       0.19      0.33      0.24       200\n",
      "weighted avg       0.31      0.56      0.40       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prani/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/prani/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/prani/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# define a function to evaluate the model\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for document, label in test_loader:\n",
    "            # document: (batch_size, seq_len)\n",
    "            # label: (batch_size)\n",
    "            document = document.to(device)\n",
    "            label = label.to(device)\n",
    "            # output: (batch_size, num_classes)\n",
    "            output = model(document)\n",
    "            # output: (batch_size)\n",
    "            output = torch.argmax(output, dim=1)\n",
    "            y_true.extend(label.tolist())\n",
    "            y_pred.extend(output.tolist())\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "# evaluate the model\n",
    "evaluate(model, test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
